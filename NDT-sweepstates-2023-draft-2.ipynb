{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc1b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "## User input\n",
    "YEAR_TO_PROCESS = 2023\n",
    "REPORT_TO_GENERATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4278e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### import statements\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  #supress warnings, i've tested the code\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import os\n",
    "import re\n",
    "import docx\n",
    "from docxcompose.composer import Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2043e5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### global definitions\n",
    "def points_from_prelims(prelim_percentage): ## taken from the ranking procedure.\n",
    "    points = 8\n",
    "    points += prelim_percentage>0\n",
    "    points += prelim_percentage>=0.21\n",
    "    points += prelim_percentage>=0.33\n",
    "    points += prelim_percentage>0.4999\n",
    "    points += prelim_percentage>0.50\n",
    "    points += prelim_percentage>=0.67\n",
    "    points += prelim_percentage>=0.80\n",
    "    points += prelim_percentage>0.9999\n",
    "    return points\n",
    "\n",
    "#I might be able to significantly speed this code up by attempting to vectorize, but do I really care?\n",
    "def winner_points_from_elims(loser_ballots): #taken from ranking procedure: unanimous elim wins (or byes) are worth 6, else 5\n",
    "    return 6-(loser_ballots>=1)\n",
    "def loser_points_from_elims(loser_ballots): #taken from ranking procedure: Showing up is worth 3 points, taking a ballot worth 4\n",
    "    return 3+(loser_ballots>=1)\n",
    "\n",
    "class Division(Enum):\n",
    "    VARSITY = 'v'\n",
    "    JUNIOR_VARSITY = 'jv'\n",
    "    NOVICE = 'n'\n",
    "    ROUND_ROBIN = 'rr'\n",
    "    TOTAL = 'total' ##hack. TODO: Remove.\n",
    "\n",
    "    \n",
    "# I could probably get away without referencing the year, but I want to be able to process last year's results to generate\n",
    "# this year's spring reports with 'movers' and 'new schools' so I plan for the future\n",
    "class tournament():\n",
    "        def __init__(self,tournament_name,tournament_year,prelim_count_vector,division_vector):\n",
    "            self.prelim_counts = prelim_count_vector\n",
    "            self.divisions = division_vector\n",
    "            self.name = tournament_name\n",
    "            self.year = tournament_year\n",
    "\n",
    "MINIMUM_SCHOOLS_PER_DIVISION = 3 #taken from the ranking procedure. all of these are checked inclusively.\n",
    "MINIMUM_TEAMS_PER_DIVISION = 6\n",
    "MINIMUM_PRELIMS_PER_DIVISION = 4\n",
    "MAXIMUM_ENTRIES_COUNTED_PER_SCHOOL = 2\n",
    "MAXIMUM_TOURNAMENTS_COUNTED_PER_SCHOOL = 8\n",
    "\n",
    "\n",
    "NDT_DISTRICTS = range(1,9,1) #1-8, not inclusive. Unlikely to change, but i'll centralize it anyway\n",
    "\n",
    "def first_or_second(): # clunky, but avoids hard-coding.\n",
    "    if REPORT_TO_GENERATE==1:\n",
    "        ordinal=\"first\"\n",
    "        season=\"fall\"\n",
    "    else:\n",
    "        ordinal=\"second\"\n",
    "        season=\"spring\"\n",
    "    return [ordinal,season]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f8de2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#may properly drop invalid divisions, will certainly at least error out if presented with an invalid division.\n",
    "#does not properly consider prelim seed in first elim round\n",
    "#does not account for 'extenuating circumstances', II.(g), needs more code\n",
    "\n",
    "# I use '3-0' to describe any unanimous win (bye, forfeit, walkover). If the scoring conditions are changed to award different\n",
    "# points for a 3-0 win than a 5-0 win (or whatever), this code will break.\n",
    "\n",
    "# compares against the defined validity conditions, returns false if any are not met.\n",
    "def is_division_valid(prelim_record,prelim_count):\n",
    "    school_count = prelim_record['School'].nunique()\n",
    "    entry_count = len(prelim_record['Code'])\n",
    "    return (school_count>=MINIMUM_SCHOOLS_PER_DIVISION) & (entry_count>=MINIMUM_TEAMS_PER_DIVISION) & (prelim_count>=MINIMUM_PRELIMS_PER_DIVISION)\n",
    "\n",
    "# Replaces elim rows with explicit walkovers, assigns a 3-0 win to the advancing entry.\n",
    "def process_elim_walkovers(elim_record):\n",
    "    elim_walkovers = pd.DataFrame()\n",
    "    elim_walkovers = elim_record[elim_record['Win'].str.contains('advances')]\n",
    "    if not elim_walkovers.empty:\n",
    "        elim_walkovers['walkover_winner'] = elim_walkovers['Win'].str[:-9]\n",
    "        elim_walkovers['aff_walks_over'] = elim_walkovers['walkover_winner'] == elim_walkovers['Aff']\n",
    "        elim_walkovers['walkover_ballot'] = elim_walkovers['aff_walks_over'].replace({True: '3-0\\tAFF', False: '3-0\\tNEG'})\n",
    "        elim_walkovers.drop(columns=['walkover_winner','aff_walks_over','Win'],axis=1,inplace=True)\n",
    "        elim_walkovers['Win'] = elim_walkovers['walkover_ballot']\n",
    "        elim_walkovers.drop('walkover_ballot',axis=1,inplace=True)\n",
    "        elim_record.drop(elim_record.index[elim_record['Win'].str.contains('advances')],inplace=True)\n",
    "        elim_record = pd.concat([elim_record,elim_walkovers[['Aff','Neg','Win']]])\n",
    "    return elim_record\n",
    "\n",
    "# Detects elim rounds where the tournament organizer has denoted an elim walkover by simply pairing two teams from the same\n",
    "# school against each other and has not published a winner. Manual intervention is required to correct these elim rounds,\n",
    "# because it's necessary to look at the next elim round to determine who actually advanced.\n",
    "def detect_implied_walkovers(elim_record):\n",
    "    elim_record['implied_walkover'] = (elim_record['Win'].isna()) & (~(elim_record['Neg'].isna())) & (~(elim_record['Aff'].isna()))\n",
    "    return elim_record['implied_walkover'].any()\n",
    "\n",
    "# replaces NaN and blanks with acceptable input for bye and walkover processing. \n",
    "# implicitly assumes that any team getting a bye is listed on the affirmative.\n",
    "def eliminate_blank_teams(elim_record):\n",
    "    elim_record\n",
    "    na_values = {'Neg': 'BLANK_ENTRY', 'Win': 'Aff BYE'}\n",
    "    elim_record.fillna(value=na_values,inplace=True)\n",
    "    return elim_record\n",
    "\n",
    "# awards a 0-3 loss for any team forfeiting an elimination round.\n",
    "def process_elim_forfeits(elim_record):\n",
    "    elim_forfeits = pd.DataFrame()\n",
    "    elim_forfeits = elim_record[elim_record['Win'].str.contains('FFT')]\n",
    "    if not elim_forfeits.empty:\n",
    "        elim_forfeits[['aff_result','neg_result']] = elim_forfeits['Win'].str.split('\\t+',expand=True)\n",
    "        elim_forfeits['aff_result'] = elim_forfeits['aff_result'].str[4:]\n",
    "        elim_forfeits['Win'] = elim_forfeits['aff_result'].replace({'FFT': '3-0\\tNEG','BYE':'3-0\\tAff'})\n",
    "        elim_record = elim_record.drop(elim_record.index[elim_record['Win'].str.contains('FFT')])\n",
    "        elim_record = pd.concat([elim_record,elim_forfeits])\n",
    "    return elim_record\n",
    "\n",
    "    \n",
    " # awards a 3-0 to the team getting a bye\n",
    "def process_elim_byes(elim_record):\n",
    "    elim_byes = pd.DataFrame()\n",
    "    elim_byes = elim_record[elim_record['Win'].str.contains('BYE')]\n",
    "    if not elim_byes.empty:\n",
    "        elim_byes[['Win','bye']] = elim_byes['Win'].str.split(' ',expand=True)\n",
    "        elim_byes['Win'] = elim_byes['Win'].str.upper()\n",
    "        elim_byes[['bye']] = elim_byes[['bye']].replace('BYE','3-0\\t')\n",
    "        elim_byes['Win'] = elim_byes['bye'] + elim_byes['Win']\n",
    "        elim_byes = elim_byes.drop('bye',axis=1)\n",
    "        elim_record = elim_record.drop(elim_record.index[elim_record['Win'].str.contains('BYE')])\n",
    "        elim_record = pd.concat([elim_record,elim_byes])\n",
    "    return elim_record\n",
    "\n",
    "# ensure hybrid entires are not awarded points. There are currently no 'NDT-recognized' hybrid teams, if any exist this function \n",
    "# will need to be modified to account for this. That change would also force me to assign a school to the hybrid team.\n",
    "def drop_hybrid_entries(tournament_points):\n",
    "    tournament_points['is_team_hybrid'] = tournament_points['Code'].str.contains('/')\n",
    "    tournament_points.drop(tournament_points[tournament_points.is_team_hybrid].index, inplace=True)\n",
    "    tournament_points.drop(['is_team_hybrid'],axis=1,inplace=True)\n",
    "    return tournament_points\n",
    "\n",
    "def process_points_division(tournament_name,year,prelim_count,division):\n",
    "    school_division_points = pd.DataFrame()\n",
    "    data_folder = 'tournament_results/'+str(year)+'/'+tournament_name\n",
    "    prelimFilePath=data_folder+'/'+tournament_name+'-'+division.value+'-prelims.csv'\n",
    "    tournament_prelims = pd.read_csv(prelimFilePath)\n",
    "    if is_division_valid(tournament_prelims,prelim_count):\n",
    "        tournament_prelims['prelim_winrate'] = tournament_prelims['Wins']/prelim_count\n",
    "        tournament_prelims['prelim_points'] = tournament_prelims['prelim_winrate'].apply(points_from_prelims)\n",
    "        tournament_points=tournament_prelims[['Code','School','prelim_points']]\n",
    "        dir_list = os.listdir(data_folder)\n",
    "        search_string = '-'+division.value+'-elim'\n",
    "        elims_to_process = filter(lambda x: re.search(search_string, x), dir_list)\n",
    "        elim_index=0\n",
    "        for elim_filename in list(elims_to_process):\n",
    "            elim_index+=1\n",
    "            points_column_header='elim_'+str(elim_index)+\"_points\"\n",
    "            elim_record=pd.read_csv(data_folder+'/'+elim_filename)[['Aff','Neg','Win']]\n",
    "            if detect_implied_walkovers(elim_record):\n",
    "                raise ValueError(\"Human intervention needed: Implied walkover in \",elim_filename)\n",
    "            elim_record = eliminate_blank_teams(elim_record)\n",
    "            elim_record = process_elim_walkovers(elim_record)\n",
    "            elim_record = process_elim_forfeits(elim_record)\n",
    "            elim_record = process_elim_byes(elim_record)\n",
    "            elim_record[['ballots','Win']] = elim_record['Win'].str.split('\\t+',expand=True) # this is inelegant, but works\n",
    "            elim_record[['winner_ballots','loser_ballots']] = elim_record['ballots'].str.split('-',expand=True) #breaks if there's not a dash in there, should be caught above\n",
    "            elim_record[['loser_ballots']] = elim_record[['loser_ballots']].astype(\"int\")\n",
    "            elim_record[['winner_points']] = elim_record[['loser_ballots']].apply(winner_points_from_elims)\n",
    "            elim_record[['loser_points']] = elim_record[['loser_ballots']].apply(loser_points_from_elims)\n",
    "            elim_record['aff_win'] = elim_record['Win'].apply(lambda y: 1 if y=='AFF' else 0)## TODO: replace sad slow apply with vectorized happy fast 'replace'\n",
    "            elim_record['neg_win'] = 1-elim_record['aff_win']\n",
    "            elim_record['aff_points'] = elim_record['winner_points']*elim_record['aff_win']+elim_record['loser_points']*elim_record['neg_win']\n",
    "            elim_record['neg_points'] = elim_record['winner_points']*elim_record['neg_win']+elim_record['loser_points']*elim_record['aff_win']\n",
    "            temp_aff = pd.DataFrame()\n",
    "            temp_neg = pd.DataFrame()\n",
    "            temp_aff[['Code',points_column_header]] = elim_record[['Aff','aff_points']]\n",
    "            temp_neg[['Code',points_column_header]] = elim_record[['Neg','neg_points']]\n",
    "            elim_points = pd.concat([temp_aff,temp_neg])\n",
    "            tournament_points = tournament_points.merge(elim_points,'left','Code')\n",
    "            tournament_points[[points_column_header]] = tournament_points[[points_column_header]].fillna(0).astype(int)\n",
    "        tournament_points = drop_hybrid_entries(tournament_points)\n",
    "        tournament_points['total_points'] = tournament_points.drop(['Code','School'],axis=1).sum(axis=1)\n",
    "        school_division_points = tournament_points[['School','total_points']].groupby('School',as_index=False).agg({'total_points': {lambda z: z.nlargest(MAXIMUM_ENTRIES_COUNTED_PER_SCHOOL).sum()}})\n",
    "        school_division_points.columns = list(map(''.join, school_division_points.columns.values))\n",
    "        school_division_points[tournament_name+'_'+division.value+'_points'] = school_division_points['total_points<lambda>']\n",
    "        school_division_points = school_division_points.drop('total_points<lambda>',axis=1)\n",
    "    return school_division_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5995f91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Functions to split tournaments into divisions, and integrate tournaments into one Big Table\n",
    "def process_points_tournament(tournament):\n",
    "    tournament_name=tournament.name\n",
    "    prelim_count_vector=tournament.prelim_counts\n",
    "    division_vector=tournament.divisions\n",
    "    year=tournament.year\n",
    "    school_tournament_points=pd.DataFrame()\n",
    "    for (division,prelim_count) in zip(division_vector, prelim_count_vector):\n",
    "        if prelim_count==0:\n",
    "            continue\n",
    "        division_points = pd.DataFrame()\n",
    "        division_points = process_points_division(tournament_name,year,prelim_count,division)\n",
    "        if school_tournament_points.empty:\n",
    "            school_tournament_points = division_points #the merge will error out if there aren't any rounds in the division (and consequently the output dataframe is empty)\n",
    "        else:\n",
    "            school_tournament_points = school_tournament_points.merge(division_points,how='outer',on='School')\n",
    "    school_tournament_points.fillna(0,inplace=True)\n",
    "    columns_to_add = school_tournament_points.loc[:,school_tournament_points.columns!='School'] #unsafe to reorder this list prior to merging\n",
    "    total_tournament_points = columns_to_add.sum(axis=1)\n",
    "    school_tournament_points[tournament_name+'_total_points'] = total_tournament_points\n",
    "    return school_tournament_points\n",
    "\n",
    "def tournament_merge(cumulative_list,new_tournament):\n",
    "    if cumulative_list.empty:\n",
    "        return new_tournament # the merge will error out if this is the first tourney processed because there's no 'school' column\n",
    "    new_cumulative_list = cumulative_list.merge(new_tournament,how='outer',on='School')\n",
    "    new_cumulative_list.fillna(0,inplace=True)\n",
    "    return new_cumulative_list\n",
    "\n",
    "def sum_legal_tournaments(cumulative_points,division,legal_tournament_count):\n",
    "    column_label_substring = '_'+division.value+'_'\n",
    "    filtered_cumulative_points = cumulative_points.filter(like=column_label_substring)\n",
    "    filtered_cumulative_points = filtered_cumulative_points.apply(pd.Series.nlargest,axis=1,n=legal_tournament_count)#this is slow, but i don't know a faster way\n",
    "    filtered_cumulative_points.fillna(0,inplace=True)\n",
    "    total_points=pd.DataFrame()\n",
    "    total_points['School'] = cumulative_points['School']\n",
    "    total_points[division.value+'_total_points'] = filtered_cumulative_points.sum(axis=1)\n",
    "    return total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22503006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### define tournaments and execute\n",
    "tournament_list=pd.read_csv('tournaments-'+str(YEAR_TO_PROCESS)+'.csv')\n",
    "\n",
    "\n",
    "cumulative_points = pd.DataFrame()\n",
    "for tournament_index,tournament_data in tournament_list.iterrows():\n",
    "    division_rounds = [tournament_data['varsity_rounds'],tournament_data['junior_varsity_rounds'],tournament_data['novice_rounds'],tournament_data['round_robin_rounds']]\n",
    "    divisions = [Division.VARSITY,Division.JUNIOR_VARSITY,Division.NOVICE,Division.ROUND_ROBIN]\n",
    "    tournament_to_process=tournament(tournament_data['tournament_name'],YEAR_TO_PROCESS,division_rounds,divisions)\n",
    "    cumulative_points = tournament_merge(cumulative_points,process_points_tournament(tournament_to_process))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95fce346",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### report generation\n",
    "# need: new schools and movers: spring-only\n",
    "def add_rank_column(dataframe):\n",
    "    dataframe['Rank'] = range(1,len(dataframe)+1) #can't just return the index, it starts at zero.\n",
    "    dataframe['Rank'] = dataframe['Rank'].astype(str)+'.'\n",
    "    columns = dataframe.columns.tolist()\n",
    "    columns = columns[-1:] + columns[:-1]\n",
    "    return dataframe[columns]\n",
    "\n",
    "total_points_column = sum_legal_tournaments(cumulative_points,Division.TOTAL,MAXIMUM_TOURNAMENTS_COUNTED_PER_SCHOOL)\n",
    "varsity_points_column = sum_legal_tournaments(cumulative_points,Division.VARSITY,MAXIMUM_TOURNAMENTS_COUNTED_PER_SCHOOL)\n",
    "sweepstakes_results_for_reports = pd.DataFrame()\n",
    "sweepstakes_results_for_reports = total_points_column.merge(varsity_points_column,how='outer',on='School').fillna(0) #some schools don't run non-varsity teams, some only run non-varsity teams\n",
    "sweepstakes_results_for_reports['NDT pts'] = sweepstakes_results_for_reports.total_total_points.astype(int) #decimal points are big ugly\n",
    "sweepstakes_results_for_reports['Varsity pts'] = sweepstakes_results_for_reports.v_total_points.astype(int)\n",
    "sweepstakes_results_for_reports.drop(columns=['v_total_points','total_total_points'],inplace=True) #gotta rename the column, gotta remove decimal points, may as well permute.\n",
    "schools_by_districts = pd.read_csv('ndt-districts-'+str(YEAR_TO_PROCESS)+'.csv',quotechar=\"'\") #for school names containing commas, like 'Massachusetts, Amherst', we need quotes.\n",
    "community_colleges = pd.read_csv('community-colleges-'+str(YEAR_TO_PROCESS)+'.csv',quotechar=\"'\")# there aren't any colleges with commas, but i gotta future-proof.\n",
    "sweepstakes_results_for_reports = sweepstakes_results_for_reports.merge(schools_by_districts,how='left',on='School')\n",
    "sweepstakes_results_for_reports = sweepstakes_results_for_reports.merge(community_colleges,how='left',on='School')\n",
    "sweepstakes_results_for_reports.fillna(value=False,inplace=True)\n",
    "sweepstakes_results_for_reports['CC'].replace({True: 'Y', False: 'N'},inplace=True) #i want to display this in a pretty way.\n",
    "\n",
    "sweepstakes_results_for_reports.to_csv(index=False,path_or_buf=\"sweepstakes_output_\"+str(YEAR_TO_PROCESS)+\"_full.csv\")\n",
    "\n",
    "sweepstakes_top10_overall = add_rank_column(sweepstakes_results_for_reports.sort_values('NDT pts',ascending=False,ignore_index=True).head(10))\n",
    "sweepstakes_top10_varsity = add_rank_column(sweepstakes_results_for_reports.sort_values('Varsity pts',ascending=False,ignore_index=True).head(10))\n",
    "sweepstakes_top10_overall_CC = add_rank_column(sweepstakes_results_for_reports[sweepstakes_results_for_reports['CC']=='Y'].sort_values('NDT pts',ascending=False,ignore_index=True))\n",
    "sweepstakes_overall_rankings = add_rank_column(sweepstakes_results_for_reports.sort_values('NDT pts',ascending=False,ignore_index=True))\n",
    "sweepstakes_varsity_rankings = add_rank_column(sweepstakes_results_for_reports.sort_values('Varsity pts',ascending=False,ignore_index=True))\n",
    "\n",
    "district_overall_sweepstakes_points = {}\n",
    "for district in NDT_DISTRICTS: #filter by district, then sort by 'overall', then add a rank column, then it's good\n",
    "    district_overall_sweepstakes_points[district] = add_rank_column(sweepstakes_results_for_reports[sweepstakes_results_for_reports['District']==district].sort_values('NDT pts',ascending=False,ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f86aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##output to word tables\n",
    "\n",
    "\n",
    "\n",
    "[report_ordinal,report_season] = first_or_second()\n",
    "season_caps=report_season.upper()\n",
    "season_sentence=report_season.capitalize()\n",
    "report_replacement_dictionary={\"$YEAR\":str(YEAR_TO_PROCESS),\"$FIRST\":report_ordinal,\"$SEASON_LOWER\":report_season,\"$SEASON_UPPER\":season_caps,\"$SEASON_SENTENCE\":season_sentence}\n",
    "\n",
    "\n",
    "def report_update_year(template_document):\n",
    "    for paragraph in template_document.paragraphs:\n",
    "        for replacement_item in report_replacement_dictionary:\n",
    "            if paragraph.text.find(replacement_item)>=0:\n",
    "                runs=paragraph.runs\n",
    "                for i in range(len(runs)):\n",
    "                    if runs[i].text.find(replacement_item)>=0:\n",
    "                        runs[i].text = runs[i].text.replace(replacement_item,report_replacement_dictionary[replacement_item])\n",
    "    for replacement_item in report_replacement_dictionary:\n",
    "        runs=template_document.sections[0].footer.paragraphs[0].runs\n",
    "        for i in range(len(runs)):\n",
    "            if runs[i].text.find(replacement_item)>=0:\n",
    "                runs[i].text = runs[i].text.replace(replacement_item,report_replacement_dictionary[replacement_item])\n",
    "        for table in template_document.tables:\n",
    "            for col in table.columns:\n",
    "                for cell in col.cells:\n",
    "                    for paragraph in cell.paragraphs:\n",
    "                        if paragraph.text.find(replacement_item)>=0:\n",
    "                            runs=paragraph.runs\n",
    "                            for i in range(len(runs)):\n",
    "                                if runs[i].text.find(replacement_item)>=0:\n",
    "                                    runs[i].text = runs[i].text.replace(replacement_item,report_replacement_dictionary[replacement_item])\n",
    "    return template_document\n",
    "        \n",
    "\n",
    "def append_word_results_table(results_document,results_dataframe,append_footers):\n",
    "    results_column_widths=[0.5,2,0.7,0.9,0.7,0.4]\n",
    "    created_table = results_document.add_table(results_dataframe.shape[0]+1,results_dataframe.shape[1],style=\"NDTSweepstakes\")\n",
    "\n",
    "    for j in range(results_dataframe.shape[-1]):\n",
    "        created_table.cell(0,j).text = results_dataframe.columns[j]\n",
    "        created_table.cell(0,j).width=docx.shared.Inches(results_column_widths[j]) #this is disgusting, but word doesn't respect widths set to entire columns.\n",
    "    \n",
    "    for i in range(results_dataframe.shape[0]):\n",
    "        for j in range(results_dataframe.shape[-1]):\n",
    "            created_table.cell(i+1,j).text=str(results_dataframe.values[i,j])\n",
    "            created_table.cell(i+1,j).width=docx.shared.Inches(results_column_widths[j]) #i hate it too.\n",
    "    \n",
    "\n",
    "    if append_footers:\n",
    "        results_document.add_paragraph('')\n",
    "        footer_table=results_document.add_table(1,1,style=\"NDTSweepstakes\") #in the default format, that's just a blue block across the bottom of the table.\n",
    "        results_document.add_paragraph('')\n",
    "    return results_document\n",
    "\n",
    "def append_table_header(results_document,title_string):\n",
    "    results_document.add_heading(title_string,level=3)\n",
    "    results_document.add_paragraph('')\n",
    "    return results_document\n",
    "\n",
    "results_document = docx.Document('sweepstakes-table-template.docx')\n",
    "results_document = report_update_year(results_document)\n",
    "\n",
    "results_document = append_table_header(results_document,\"Top 10 Overall Rankings\")\n",
    "results_document = append_word_results_table(results_document,sweepstakes_top10_overall,True)\n",
    "\n",
    "results_document = append_table_header(results_document,\"Top 10 Varsity Rankings\")\n",
    "results_document = append_word_results_table(results_document,sweepstakes_top10_varsity,True)\n",
    "\n",
    "results_document = append_table_header(results_document,\"Top CC Rankings\")\n",
    "results_document = append_word_results_table(results_document,sweepstakes_top10_overall_CC,True)\n",
    "results_document.add_page_break()\n",
    "\n",
    "results_document = append_table_header(results_document,\"Overall Rankings\")\n",
    "results_document = append_word_results_table(results_document,sweepstakes_overall_rankings,True)\n",
    "results_document.add_page_break()\n",
    "\n",
    "results_document = append_table_header(results_document,\"Varsity Rankings\")\n",
    "results_document = append_word_results_table(results_document,sweepstakes_varsity_rankings,True)\n",
    "results_document.add_page_break()\n",
    "\n",
    "results_document = append_table_header(results_document,\"Overall Rankings by District\")\n",
    "for district in NDT_DISTRICTS:\n",
    "    results_document = append_word_results_table(results_document,district_overall_sweepstakes_points[district],False)\n",
    "    results_document.add_paragraph('')\n",
    "footer_table=results_document.add_table(1,1,style=\"NDTSweepstakes\")\n",
    "results_document.add_paragraph('')\n",
    "results_document.add_page_break()\n",
    "\n",
    "results_composer=Composer(results_document)\n",
    "procedure_document=docx.Document('sweepstakes-procedure.docx')\n",
    "\n",
    "results_composer.append(procedure_document)\n",
    "\n",
    "results_composer.save('test_document.docx')#'NDT-sweepstakes_tables_'+str(YEAR_TO_PROCESS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
